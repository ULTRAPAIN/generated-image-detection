{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IlH6JdUgu1pL"
   },
   "source": [
    "# Pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "riwOyFdvyUqW",
    "outputId": "6806a4dc-97d0-43fd-873c-715c717c2beb"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')\n",
    "# !pip install -q kaggle\n",
    "# !mkdir ~/.kaggle\n",
    "# !cp kaggle.json ~/.kaggle/\n",
    "# !chmod 600 ~/.kaggle/kaggle.json\n",
    "# ! kaggle datasets download xhlulu/140k-real-and-fake-faces\n",
    "# ! unzip 140k-real-and-fake-faces.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Sh8PurTu1pP"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AX6fDSB5u1pU",
    "outputId": "a67cf692-307a-45ff-b73b-b17abcd08cb8"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3GXMi1ycu1pV",
    "outputId": "aaa16c2e-d7c1-4074-9ffa-ed92f7ac7f27"
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qt6xH9_ou1pW"
   },
   "source": [
    "## Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bmum1CVhgX-D"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import BinaryCrossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wRYKqkFEgX-D"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "image_height = 64\n",
    "image_width = 64\n",
    "latent_features = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5s8Ue6_ngX-D",
    "outputId": "bdeb52d4-1a47-4ccb-c02d-1d6fc8fb77c8"
   },
   "outputs": [],
   "source": [
    "generator = load_model(\"models/generator.keras\")\n",
    "\n",
    "generator.compile(optimizer=Adam(learning_rate=0.0002,beta_1=0.5),\n",
    "                      loss=BinaryCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_k_kUY3CgX-E",
    "outputId": "f06c0215-3036-4397-e26b-b47a5b6f9463"
   },
   "outputs": [],
   "source": [
    "# Generating the fake images training data from the generator\n",
    "def save_fake(output_dir,num_images=1000):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    generated_images = generator.predict(tf.random.normal((num_images, latent_features, 1)),verbose=0)\n",
    "\n",
    "    for i in range(num_images):\n",
    "        image = generated_images[i]\n",
    "        image = (image + 1) / 2\n",
    "        image_path = os.path.join(output_dir, f\"{i}.jpg\")\n",
    "        tf.keras.preprocessing.image.save_img(image_path, image)\n",
    "\n",
    "    print(f\"{i + 1} images generated and saved to {output_dir}.\")\n",
    "\n",
    "save_fake(\"resnet_data/train/0\",num_images=25000)\n",
    "save_fake(\"resnet_data/valid/0\",num_images=5000)\n",
    "save_fake(\"resnet_data/test/0\",num_images=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "phXpWmUxgX-E",
    "outputId": "45cdadda-c26e-47aa-f6ee-389a8ff03a2d"
   },
   "outputs": [],
   "source": [
    "# Saving the real images in a different directory\n",
    "def save_real(source_dir, destination_dir, num_images=1000):\n",
    "    real_folder = os.path.join(source_dir, 'real')\n",
    "    image_paths = [os.path.join(real_folder, filename) for filename in os.listdir(real_folder)]\n",
    "\n",
    "    if not os.path.exists(destination_dir):\n",
    "        os.makedirs(destination_dir)\n",
    "\n",
    "    image_counter = 0\n",
    "    for i, file_path in enumerate(image_paths):\n",
    "        with Image.open(file_path) as img:\n",
    "            output_path = os.path.join(destination_dir, f\"{i}.jpg\")\n",
    "            img.save(output_path)\n",
    "            image_counter += 1\n",
    "        if image_counter >= num_images:\n",
    "                break\n",
    "    print(f\"{num_images} images saved from {source_dir}to {destination_dir}.\")\n",
    "\n",
    "save_real('real_vs_fake/real-vs-fake/train', \"resnet_data/train/1\", num_images=25000)\n",
    "save_real('real_vs_fake/real-vs-fake/valid', \"resnet_data/valid/1\", num_images=5000)\n",
    "save_real('real_vs_fake/real-vs-fake/test', \"resnet_data/test/1\", num_images=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S_PyY0MugX-E",
    "outputId": "b3e7d48c-08bf-42f4-fb67-e6feaeb7278e"
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"resnet_data/train\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"binary\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(image_height, image_width),\n",
    "    interpolation='gaussian',\n",
    "    shuffle=True,\n",
    "    seed=69,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o5PZgQ6hgX-E",
    "outputId": "d4654e62-ba1e-4a77-f1d9-d80f0a2676a2"
   },
   "outputs": [],
   "source": [
    "valid_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"resnet_data/valid\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"binary\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(image_height, image_width),\n",
    "    interpolation='gaussian',\n",
    "    shuffle=True,\n",
    "    seed=69,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XKitxhZBgX-F",
    "outputId": "e17dbd47-4536-40c8-e9a2-44b07ea35f84"
   },
   "outputs": [],
   "source": [
    "test_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"resnet_data/test\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"binary\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(image_height, image_width),\n",
    "    interpolation='gaussian',\n",
    "    shuffle=True,\n",
    "    seed=69,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FzmeZajmgX-F"
   },
   "outputs": [],
   "source": [
    "def augument(x, y):\n",
    "    img = tf.cast(x, tf.float32)\n",
    "    img = (img - 127.5) / 127.5\n",
    "    return img, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kHcfwtnZgX-F"
   },
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.map(augument)\n",
    "valid_dataset = valid_dataset.map(augument)\n",
    "test_dataset = test_dataset.map(augument)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Label '1' is real\n",
    "- Label '0' is fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 205
    },
    "id": "LRtCtqvZu1pZ",
    "outputId": "9700139f-9485-4825-fa60-4064565ba2d6"
   },
   "outputs": [],
   "source": [
    "for batch, labels in train_dataset.take(1):\n",
    "    batch = (batch + 1) / 2\n",
    "    num_images = 3\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(1,num_images,i+1)\n",
    "        plt.imshow(batch[i])\n",
    "        plt.title(f\"Label:{labels[i]}\")\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pElrviyOu1pa"
   },
   "source": [
    "## EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mrp2lPvmu1pa"
   },
   "outputs": [],
   "source": [
    "from keras.applications import EfficientNetB0\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "USGrVxreu1pb",
    "outputId": "7459dd1a-c8a8-49ee-8b70-d00c0a0e3624"
   },
   "outputs": [],
   "source": [
    "base_model = EfficientNetB0(weights='imagenet', include_top=False)\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "effnet_clf = Model(inputs=base_model.input, outputs=predictions)\n",
    "effnet_clf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fnUCLrfqu1pc"
   },
   "outputs": [],
   "source": [
    "save_callback = ModelCheckpoint('effnet_clf_cp.keras'\n",
    "                                ,save_weights_only=False\n",
    "                                ,monitor='val_loss'\n",
    "                                ,save_best_only=True)\n",
    "\n",
    "effnet_clf.compile(optimizer=Adam()\n",
    "                   ,loss='binary_crossentropy'\n",
    "                   ,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e3CHOqxEu1pc",
    "outputId": "24788752-7fc4-4122-9807-4bcb6e28f845"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "effnet_clf_history = effnet_clf.fit(\n",
    "    train_dataset,\n",
    "    epochs=100,\n",
    "    validation_data=valid_dataset,\n",
    "    # callbacks=[save_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "id": "LKEi1gNKI6uN",
    "outputId": "c81dc9f4-0523-4f20-c747-6cf56db6bb6c"
   },
   "outputs": [],
   "source": [
    "# Visualizing results\n",
    "training_loss = effnet_clf_history.history['loss']\n",
    "validation_loss = effnet_clf_history.history['val_loss']\n",
    "training_accuracy = effnet_clf_history.history['accuracy']\n",
    "validation_accuracy = effnet_clf_history.history['val_accuracy']\n",
    "epochs = range(1, len(training_loss) + 1)\n",
    "\n",
    "# Plotting Loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, training_loss, label='Training loss')\n",
    "plt.plot(epochs, validation_loss, label='Validation loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plotting Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, training_accuracy, label='Training Accuracy')\n",
    "plt.plot(epochs, validation_accuracy, label='Validation Accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ULvji5g1u1pd"
   },
   "outputs": [],
   "source": [
    "# Testing set\n",
    "best_effnet_clf = load_model(\"effnet_clf_cp.h5\")\n",
    "test_loss, test_accuracy = best_effnet_clf.evaluate(test_dataset, verbose=0)\n",
    "print(f\"Test loss:{test_loss}\")\n",
    "print(f\"Test accuracy:{test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN discriminator architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.initializers import RandomNormal\n",
    "from keras.models import Sequential\n",
    "from keras import layers, optimizers, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = RandomNormal(stddev=0.02, seed=69)\n",
    "discriminator = Sequential([\n",
    "    layers.Conv2D(32, 4, 2, padding='same', input_shape = (image_width,image_height,3), \n",
    "                  kernel_initializer=init, use_bias=False),\n",
    "    layers.LeakyReLU(0.2),\n",
    "    layers.Dropout(0.25),\n",
    "\n",
    "    layers.Conv2D(64, 4, 2, padding='same', kernel_initializer=init, use_bias=False),\n",
    "    layers.LeakyReLU(0.2),\n",
    "    layers.Dropout(0.25),\n",
    "\n",
    "    layers.Conv2D(128, 4, 2, padding='same', kernel_initializer=init, use_bias=False),\n",
    "    layers.LeakyReLU(0.2),\n",
    "    layers.Dropout(0.25),\n",
    "\n",
    "    layers.Conv2D(256, 4, 2, padding='same', kernel_initializer=init, use_bias=False),\n",
    "    layers.LeakyReLU(0.2),\n",
    "    layers.Dropout(0.25),\n",
    "\n",
    "    layers.Conv2D(512, 4, 2, padding='same', kernel_initializer=init, use_bias=False),\n",
    "    layers.LeakyReLU(0.2),\n",
    "    layers.Dropout(0.25),\n",
    "\n",
    "    layers.Conv2D(1024, 2, 1, kernel_initializer=init, use_bias=False),\n",
    "    layers.LeakyReLU(0.2),\n",
    "    layers.Dropout(0.25),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "discriminator.compile(optimizer=optimizers.Adam(learning_rate=0.0002,beta_1=0.5),\n",
    "                      loss=losses.BinaryCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_callback = ModelCheckpoint('discriminator_non_gan_cp.h5'\n",
    "                                ,save_weights_only=False\n",
    "                                ,monitor='val_loss'\n",
    "                                ,save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.backend.clear_session()\n",
    "discriminator_history = discriminator.fit(\n",
    "    train_dataset,\n",
    "    epochs=500,\n",
    "    validation_data=valid_dataset,\n",
    "    callbacks=[save_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing results\n",
    "training_loss = discriminator_history.history['loss']\n",
    "validation_loss = discriminator_history.history['val_loss']\n",
    "training_accuracy = discriminator_history.history['accuracy']\n",
    "validation_accuracy = discriminator_history.history['val_accuracy']\n",
    "epochs = range(1, len(training_loss) + 1)\n",
    "\n",
    "# Plotting Loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, training_loss, label='Training loss')\n",
    "plt.plot(epochs, validation_loss, label='Validation loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plotting Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, training_accuracy, label='Training Accuracy')\n",
    "plt.plot(epochs, validation_accuracy, label='Validation Accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing set\n",
    "best_discriminator = load_model(\"discriminator_non_gan_cp.h5\")\n",
    "test_loss, test_accuracy = best_discriminator.evaluate(test_dataset, verbose=0)\n",
    "print(f\"Test loss:{test_loss}\")\n",
    "print(f\"Test accuracy:{test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xaJy5W4gu1pe"
   },
   "source": [
    "Manual testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JzKk2Jxbu1pe"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "24X7s4J3YBmh"
   },
   "outputs": [],
   "source": [
    "def manual_prediction(img_path, model):\n",
    "  img = image.load_img(img_path, target_size=(image_height, image_width))\n",
    "  img_array = image.img_to_array(img)\n",
    "  img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "  # Normalize pixel values to be between 0 and 1\n",
    "  img_array /= 255.0\n",
    "\n",
    "  # Make predictions\n",
    "  prediction = model.predict(preprocess_input(img_array))\n",
    "\n",
    "  plt.imshow(img)\n",
    "  plt.title(f\"Label:{prediction[0][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N7Xj9gPPYOWn"
   },
   "outputs": [],
   "source": [
    "manual_prediction(\"manual_test_images/Hard.jpeg\",best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jt9rKRVdu1ph"
   },
   "outputs": [],
   "source": [
    "manual_prediction(\"manual_test_images/Medium.jpg\",best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rwVi2K4wYckX"
   },
   "outputs": [],
   "source": [
    "manual_prediction(\"manual_test_images/Easy.jpg\",best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-AB8KxPcYkpi"
   },
   "outputs": [],
   "source": [
    "manual_prediction(\"manual_test_images/Real.jpg\",best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MM4KL_lkY3rC"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
